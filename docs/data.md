# Data

This document outlines the data retrieved and used in this project, and explains how the data is stored and accessed by the code.

## Data repository

The ShotLink data is private and only accessible to people that have been ok'd by the PGA Tour. As a result, we keep the data in a private repo to which only we have access. The public repo includes this private repo as a [Git submodule](https://git-scm.com/book/en/v2/Git-Tools-Submodules) and, since by default a git clone automatically clones the contents of submodules, can access the data using the `data` directory. The ShotLink data is explained in more detail below in the [ShotLink data](#shotlink-data) section. 

## ShotLink data

[ShotLink](https://www.pgatour.com/stats/shotlinkintelligence/overview.html) contains detailed information about every stroke taken on most PGA Tour events, over many years. It's available for use in academic environments as specified on the ShotLink site. Each of the members of our project team obtained permission to use the data, and we stored the data in a separate and private GitHub repo.

We chose to use the following ShotLink datasets. All of these are accessible using the PGA Tour's "Stat Inquiry System", using the "Detail Export" option from the "Tool" section. Where possible - strokes, holes, rounds, events - we used the pre-generated by-year data sets. In cases where pre-generated datasets weren't available we requested the data by year using the site's "filtered export" functionality.
- **Stroke level**. This data set has a row per shot/stroke taken on each PGA Tour event, and provides the majority of the ShotLink data we use. We store it in the root directory of the data repository as a compressed .zip file per year - for example, `Shot2017.TXT.zip`, `Shot2016.TXT.zip` - and unzip the data into semicolon-delimited text files - with names like `Shot2017.TXT` - by running the unzip.py script in the same directory.
- **Course level**. This data set contains supplemental data about the courses, such as the width of the fairway at various distances, measures of the height of the grass in various locations, a measure of the speed of the green using a [Stimpmeter](https://en.wikipedia.org/wiki/Stimpmeter), and more. We join it with the shot data to provide additional information that might be relevant when analyzing shot performance. Like with the stroke data, we store it as compressed files with names like CourseLevel2017.TXT.zip and then unzip after cloning the repo and before doing analysis.

We also evaluated the following datasets and chose not to use them - mainly because the majority of the data they hold is summaries of the data that exists in more granular form in the stroke data set, in the case of holes, rounds, and events, or because the data wasn't applicable to the analysis we we performed, in the case of radar launch and trajectory.

- Holes
- Rounds
- Events
- Radar launch
- Radar trajectory

We only need weather data on the days during which a tournament was held. To get this data, the [get_course_active_dates.py](../pygolfdata/data/get_course_active_dates.py) script calls the [shotlink.py](../pygolfdata/data/shotlink.py) `get_active_course_dates` function. This function returns a DataFrame that has a list of course names and dates, with a row per combination of day and course during which a tournament was played.

In addition to the data in the root directory, the data repo also has data used by `shotlink.py` module unit tests, in the `test` directory. These files are very small subsets of the complete data - so they load quickly, for example - that we generated using the `generate_test_files.py` or `generate_test_files.sh` scripts in the root directory of the data repo.

## Weather data

The weather data comes from Dark Sky; the data source and the code we use is explained in more detail in the [weather API doc](weather_date_api_doc.md). 

The [get_combined_weather_and_course_data.py](../pygolfdata/data/get_combined_weather_and_course_data.py) script obtains weather observations for the specific geographic coordinates and dates associated with each tournament. It outputs the results as `pga_tour_weather_data.csv`, which exists in the root directory of the data repo. For more information about the entire process, see the [Combination of geo-coded course location, weather, and ShotLink data](#combination-of-geo-coded-course-location-weather-and shotlink-data) section below.

In addition, the weather code uses test data located in the main repo, in the [test_data](../pygolfdata/weather/test_data) directory.

## Course location

To obtain weather observations, we need a the latitude and longitude of each course. The [get_course_locations.py](../pygolfdata/data/get_course_locations.py) script uses Google's geocoding API to find the latitude and longitude and outputs the result as a mapping between course name and latitude/longitude to the file `courses_geocoded.txt` in the data repo.

## Combination of geo-coded course location, weather, and ShotLink data

Ultimately, we produce a dataset with a row per stroke, where each row includes data about the stroke and data about the weather at the time the stroke was taken (to the nearest hour). We persist this data in the root directory of the data repo as files like `combined2012to2016.zip`, which extracts to the file `combined_shots_and_weather_2012_2016.csv` and holds a row per stroke from 2012 to 2016, inclusive. The `shotlink.py` module provides a convenience function called `get_combined_data_from_file` that loads the data from this file and returns a pandas DataFrame, specifying explicit data types to greatly reduce the size of the data in memory.

To get to this data set, we run the following code, all of which is introduced above:
- [get_course_locations.py](../pygolfdata/data/get_course_locations.py) - The latitude and longitude of each course. Produces `courses_geocoded.txt`.
- [get_course_active_dates.py](../pygolfdata/data/get_course_active_dates.py) - The dates on which a tournament was held, at a given course. We only need weather data for a particular course these particular days. Produces `active_course_dates.csv`.
- [get_combined_weather_and_course_data.py](../pygolfdata/data/get_combined_weather_and_course_data.py) - Weather observations for each hour of each day on which a tournament was held, at the specified course (i.e., at the latitude and longitude of the course). Produces `pga_tour_weather_data.csv`.
- [get_combined_shot_and_weather_data.py](../pygolfdata/data/get_combined_shot_and_weather_data.py) - Combines stroke data from the `shotlink.py` get_shots_augmented function and weather data from `pga_tour_weather_data.csv` to generate the ultimate data sets available for analysis. Produces `combined_shots_and_weather_yearfrom_yearto.csv` and the corresponding compressed files stored in the data repo.

## Git submodules, Travis CI access to the private data repository

This section explains how we got a Travis CI build working with both a public GitHub repo and a private GitHub repo, using Git submodules and GitHub's and Travis CI's support for deploy keys. You can do this without paying anything, as of May 2018.

As explained above in the [Data repository](#data-repository) section, we store the PGA Tour ShotLink data in a private GitHub repo, separate from the code that lives in a public repo. We want the code in the public repo to have access to and know where the data lives, and for this to be true whether the code runs on a local machine or on a CI VM. 

The local machine is easy: as long as you have access to the data repo, when you clone the main repo, you'll automatically get the contents of the data repo - the data exists in the `data` directory. 

For the Travis CI machine, it's more complicated. Travis is free for public repos, and this project's public, so Travis can do builds, for free. However, we want our builds to have access to private data - to the data in the private repo that exists as a submodule in the data directory. 

One possibility - this may work, but we haven't tried it - could be to make the core repo private, and pay Travis. We want the core repo to be public, and we don't want to pay Travis (this is a student/class project). 

So, we instead chose to use GitHub ['deploy keys'](https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys). In a nutshell, we create a new SSH public/private key pair, we tell GitHub the public side of this key (using the github.com web UI), and we make sure the Travis CI build has access to the private side of the key. Then, when Travis pulls down the public repo it can get the private repo too.

How does Travis get the private key? Travis supports what it calls 'user keys', as documented on the [Travis CI private dependencies](https://docs.travis-ci.com/user/private-dependencies/) page. This would let us just upload the key. However, user keys only work on private repos. 

Instead, we encrypt the private side of the GitHub key - locally, on a client machine - using the public key associated with the Travis CI build (each Travis CI build has a public/private key pair, created by Travis). Then we check the encrypted key into the public repo. During the build - running on the Travis CI VM - we decrypt the key and add it to the ssh-agent. After this prep, git clone - again, running on the VM - is able to succesfully retrieve the contents of the private repo. 

A few more details:
- To get the new key we use with GitHub - the one whose public key goes in the private repo's deploy keys section, and whose private key gets encrypted and checked in to the public repo - we follow the [instructions on the GitHub site](https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent). We just need the first part, since we only want the files (there's no need to use ssh-agent on the machine we use to just generate the key). For example, I ran `ssh-keygen -t rsa -b 4096 -C "TravisDeployKey"` and saved the result using the string TravisDeployKey, which produced two files: `TravisDeployKey` and `TravisDeployKey.pub`.
- Then I encrypted the `TravisDeployKey` file by following [these steps](https://docs.travis-ci.com/user/encrypting-files) on the Travis CI site. First I installed the travis Ruby gem by running `sudo gem install travis`. Then I rand `travis login` and then `travis encrypt-file TravisDeployKey` (again, `TravisDeployKey` is the name of the file that contains the private side of the GitHub SSH key). This gave me a `TravisDeployKey.enc` file and the exact code to use in the `.travis.yml` file to decrypt the key. I checked in the `TravisDeployKey.enc` file to the public repo. This is ok because, since it's encrypted, only the Travis CI build - the only place that has the private key with which it's encrypted - can decrypt it.
- Finally, I updated the [.travis.yml](../.travis.yml) configuration/build steps file to call openssl, chmod, start ssh-agent, and then ssh-add the decrypted key. I put these steps in the `before_install` section. At this point the repo's already been cloned (without submodules, because I've specified `submodules: False` elsewhere in the file), and so I can run `git submodule update --init --recursive` to actually get the contents of the submodule.